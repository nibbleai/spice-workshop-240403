{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/title.png\" width=\"800px\"/>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# Experiments\n",
    "\n",
    "In this notebook, we explore data and experiment iteratively.\n",
    "\n",
    "## Part 1 - Data Exploration\n",
    "\n",
    "2 datasets are used:\n",
    "- TLC NYC Taxi trips (2015) - [link](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)\n",
    "- NOAA Climate data of JFK airport, NYC (2015) - [link](https://www.ncei.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00094789/detail)\n",
    "\n",
    "### TLC NYC Taxi trips\n",
    "Contains taxi trips, whose duration we seek to predict.\n",
    "<br><br>\n",
    "\n",
    "| Column name | Description |\n",
    "| :- | :- |\n",
    "| vendor_id | TPEP provider that provided the record |\n",
    "| pickup_datetime | The start date of the ride |\n",
    "| dropoff_datetime | The end date of the ride |\n",
    "| passenger_count | Number of passenger |\n",
    "| trip_distance | The distance in Mile of the ride |\n",
    "| pickup_longitude | The longitude of starting point of the ride |\n",
    "| pickup_latitude | The latitude of starting point of the ride |\n",
    "| rate_code | The rate code |\n",
    "| store_and_fwd_flag | Trip record held in vehicle memory before sending to the vendor |\n",
    "| dropoff_longitude | The longitude of end point of the ride |\n",
    "| dropoff_latitude | The longitude of end point of the ride |\n",
    "| payment_type | Type of payment |\n",
    "| fare_amount | Amount of the ride in dollars |\n",
    "\n",
    "More details on data schema on the [NYC TLC website](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)\n",
    "\n",
    "\n",
    "### NOAA Climate data of JFK airport, NYC\n",
    "Contains weather information.\n",
    "Most 'important' columns are:\n",
    "<br><br>\n",
    "\n",
    "| Column name | Description |\n",
    "| :- | :- |\n",
    "| TMAX | Maximum temperature |\n",
    "| TMIN | Minimum temperature |\n",
    "| PRCP | Precipitation |\n",
    "| SNOW | Snowfall |\n",
    "| SNWD | Snow depth |\n",
    "| ACMH | Average cloudiness midnight to midnight |\n",
    "| TSUN | Total sunshine for the period |\n",
    "| AWND | Average wind speed |\n",
    "\n",
    "Full data schema is available on the [NOAA website](https://www.ncei.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00094789/detail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging is disabled to avoid uncomfortable logs from third party libraries\n",
    "import logging\n",
    "\n",
    "logging.disable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import get_train_dataset\n",
    "\n",
    "data = get_train_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ydata_profiling as pandas_profiling\n",
    "\n",
    "pandas_profiling.ProfileReport(data).to_widgets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "from src.schemas import TaxiColumn\n",
    "\n",
    "NYC_COORDINATES = [40.767937, -73.982155]\n",
    "MAP_TILES = \"cartodb positron\"\n",
    "\n",
    "nyc_map = folium.Map(location=NYC_COORDINATES, tiles=MAP_TILES)\n",
    "\n",
    "pickup_coordinates = data[[TaxiColumn.PICKUP_LAT, TaxiColumn.PICKUP_LON]].values.tolist()\n",
    "dropoff_coordinates = data[[TaxiColumn.DROPOFF_LAT, TaxiColumn.DROPOFF_LON]].values.tolist()\n",
    "\n",
    "pickup_gradient = {.33: 'red', .66: 'red', 1: 'red'}\n",
    "dropoff_gradient = {.33: 'blue', .66: 'blue', 1: 'blue'}\n",
    "\n",
    "HeatMap(dropoff_coordinates, radius=1, blur=2, gradient=dropoff_gradient).add_to(nyc_map)\n",
    "HeatMap(pickup_coordinates, radius=1, blur=2, gradient=pickup_gradient).add_to(nyc_map)\n",
    "\n",
    "display(nyc_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import DualMap\n",
    "\n",
    "nyc_map = DualMap(location=NYC_COORDINATES, tiles=MAP_TILES)\n",
    "\n",
    "for hour, sub_map in [(23, nyc_map.m1), (8, nyc_map.m2)]:\n",
    "    filtered = data[data[TaxiColumn.PICKUP_TIME].dt.hour == hour]\n",
    "    train_pickup = filtered[[TaxiColumn.PICKUP_LAT, TaxiColumn.PICKUP_LON]].values.tolist()\n",
    "    train_dropoff = filtered[[TaxiColumn.DROPOFF_LAT, TaxiColumn.DROPOFF_LON]].values.tolist()\n",
    "\n",
    "    HeatMap(train_dropoff, radius=1, blur=1, gradient=dropoff_gradient).add_to(sub_map)\n",
    "    HeatMap(train_pickup, radius=1, blur=1, gradient=pickup_gradient).add_to(sub_map)\n",
    "\n",
    "display(nyc_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMapWithTime\n",
    "\n",
    "nyc_map = folium.Map(location=NYC_COORDINATES, tiles=MAP_TILES)\n",
    "\n",
    "hour_data = [\n",
    "    (\n",
    "        data\n",
    "        .loc[data['pickup_datetime'].dt.hour == hour]\n",
    "        .loc[:, [TaxiColumn.PICKUP_LAT, TaxiColumn.PICKUP_LON]]\n",
    "        .values.tolist()\n",
    "    )\n",
    "    for hour in range(24)\n",
    "]\n",
    "\n",
    "\n",
    "HeatMapWithTime(hour_data, radius=8, blur=1).add_to(nyc_map)\n",
    "\n",
    "display(nyc_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "N_CLUSTERS = 8\n",
    "COLORS = ['red', 'green', 'blue', 'yellow', 'purple', 'black', 'orange', 'cyan']\n",
    "\n",
    "pickup_coordinates = data[[TaxiColumn.PICKUP_LAT, TaxiColumn.PICKUP_LON]]\n",
    "\n",
    "kmeans = KMeans(N_CLUSTERS)\n",
    "clusters = kmeans.fit_predict(pickup_coordinates)\n",
    "\n",
    "nyc_map = folium.Map(location=NYC_COORDINATES, tiles=MAP_TILES)\n",
    "\n",
    "for cluster in range(N_CLUSTERS):\n",
    "    cluster_coordinates = pickup_coordinates[clusters == cluster].values.tolist()\n",
    "    color = COLORS[cluster]\n",
    "    HeatMap(cluster_coordinates, radius=1, blur=1, gradient={.33: color, .66: color, 1: color}).add_to(nyc_map)\n",
    "    folium.Circle(kmeans.cluster_centers_[cluster], radius=1000, color=color).add_to(nyc_map)\n",
    "\n",
    "nyc_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import get_target\n",
    "\n",
    "target = get_target(data)\n",
    "target.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Base features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.schemas import TaxiColumn\n",
    "\n",
    "COLS_TO_EXTRACT = [\n",
    "    TaxiColumn.VENDOR_ID,\n",
    "    TaxiColumn.PASSENGER_COUNT,\n",
    "    TaxiColumn.PICKUP_LON,\n",
    "    TaxiColumn.PICKUP_LAT,\n",
    "    TaxiColumn.DROPOFF_LON,\n",
    "    TaxiColumn.DROPOFF_LAT,\n",
    "]\n",
    "\n",
    "features = data.loc[:, COLS_TO_EXTRACT]\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "model = RandomForestRegressor(random_state=RANDOM_STATE).fit(features, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sorted_idx = model.feature_importances_.argsort()\n",
    "\n",
    "plt.barh(model.feature_names_in_[sorted_idx], model.feature_importances_[sorted_idx])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 : Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "model = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "splitter = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "\n",
    "cv_losses = cross_validate(\n",
    "    model,\n",
    "    features,\n",
    "    target,\n",
    "    scoring='neg_mean_squared_log_error',\n",
    "    cv=splitter,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_losses).agg(['mean', 'std'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/nibble.png\" width=\"300px\"/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
